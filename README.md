# House-Prices
House prices regression 
# House Prices - Advanced Regression Techniques
In this kaggle competition [Link](https://www.kaggle.com/c/house-prices-advanced-regression-techniques), participants are challenged to predict the final house prices with 79 explanatory variables describing almost every aspect of residential homes in Ames, lowa. 

Because this is my very first machine learning project, I focused primarily on adopting a systematic approach toward machine learning problems. This kernel contains the entire process including data exploration, data engineering, and modeling. Several base models which include Lasso, KernelRidge, GradientBoostingRegressor, XGBRegressor, and LGBRegressor were explored and fine-tuned for better prediction results. Additionlly, I experimented with two basic model stacking methods which resulted in the final model with the lowest rmse.
# Files Description
* data_description.txt - The explanations of the columns (variables)
* house_practice_new.ipynb - jupyter notebook file
* sample_submission.csv - submission sample for the Kaggle competition
* submission - all the submission csv files
* data - all the data downloaded from Kaggle
# References
* [Comprehensive data exploration with Python](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)
* [Stacked Regressions : Top 4% on LeaderBoard](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard)
* [Regularized Linear Models](https://www.kaggle.com/apapiu/regularized-linear-models)
